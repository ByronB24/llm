def business_chat(message: str, history: list, llm_chat_engine) -> str:
    """
    Handles a user message and returns a response using the provided chat engine.

    Parameters
    ----------
    message : str
        The user message or query.
    history : list
        Chat history (unused here but required for Gradio ChatInterface compatibility).
    llm_chat_engine : Any
        An LLM-based chat engine object (e.g. LlamaIndex chat engine) with `.chat()` method.

    Returns
    -------
    str
        Response string generated by the chat engine.
    """
    try:
        stream = llm_chat_engine.stream_chat(message)

        response_text = ""

        for token in stream.response_gen:
            response_text += token
            yield response_text

    except Exception as e:
        return f"Error generating response: {str(e)}"